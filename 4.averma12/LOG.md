# -100DaysofMLCode
This is 100 days of ML code in collaboration with the folks at Mumbai School of AI. It will complement my work
in my own repo github.com/averma12

# Day 1
 Revised on file operations in Python using the os and pathlib modules.
 Also downloaded zip using python and unpacked it. Took reference from the fast.ai library.
 Did eda on data downloaded.
 Day1 trying to do Facial Kepypoints Detection project again from scratch using Pytorch.
 https://github.com/averma12/Beginning_Data_Science/blob/master/Download%20and%20unpack%20requests.ipynb
 
 # Day 2
  Read on Data Augmentation techniques and Image Transforms. Looked at various forms of Data Augmentation techniques. tried to implement some of them in facial keypoints detection. Still working on them. Will update github
   link when complete.
   Links referred to
   https://blog.paperspace.com/data-augmentation-for-bounding-boxes/
   https://stackoverflow.com/questions/49659236/rotating-keypoints-numpy-array
   
# Day 3
      Built on day 2 of Data Augmentation techniques.
      Read on histogram equalization,mormalization,Gaussian blurring.
      Found out limitations of techniques I can apply on current project.
      Onwards to day 4 , defining model, data loader.
      https://github.com/averma12/Beginning_Data_Science/blob/master/View%20Image%20and%20Transforms.ipynb
      
# Day 4
     Introduction to datasets and dataloaders in pytorch. Combining them with transforms.
     Also introduced to databunch in fast.ai. Will look more into it tomorrow

# Day 5
    Read about dataloaders and datasets . Read about fast.ai databunch which is a combination of a dataloader and transforms for passing onto the model. Implementing a MNIST example using a Resblock and the databunch API. To use that later for facial keypoints project
    
    Key Points
    DataLoaders.
    Class Objects and class methods.
    Using on MNIST example.
    Code to follow soon
    
# Day 6
  https://github.com/averma12/Deep-Learning/blob/master/MNIST_ResBlocks.ipynb
  Code completed.
  
# Day 7
     Travelling Rest Day


# Day 8,9 (10-11 Jan)
  Travelling so no progress


# Day 10
 Completed Type hinting in Python.
 https://github.com/averma12/Beginning_Data_Science/blob/master/Type%20Hinting%20in%20Python.ipynb
 
 
# Day 11
 Generators and Iterators in Pyhton. Building blocks of dataloaders and datasets. Completed iterator class implementation. Doing generators now.
 
# Day 12
Generators. Data processing with pandas revision.
Signed up to be School of AI dean . Hope for the best

# Day 13
Rest

# Day 14
  Bayes Theorem. Bayesian classification to classify documents based on tags
  https://towardsdatascience.com/tagging-documents-based-on-important-words-92bee9baa310
  
  
  
  
# Day 15
  NLP nanodegree udacity regex , beautifulsoup and text normalization
  
# Day 16
  Learnt about bayes theorem.
  Extended bayes theorem in the naive bayes algorithm.
  Applied naive bayes from scratch on a sample problem and then using sklearn
  https://github.com/averma12/Deep-Learning/tree/master/Machine_Learning_algorithms_scratch/Naive%20Bayes
  
# Day 17
   Read about Hidden Markov Models
   Viterbi algorithm
   Intro to dynamic programming
   
   
# Day 18
   Read in detail about Viterbi algorithm
   Used it on an example
   Cached recursion in dynamic programming
   Itertools library in python
   Used new dunder method to create singleton in pyhton
   
# Day 19
Reviewed word2vec and word embeddings .
need to do more work on this and finsih markov model project

# Day 20
Reviewed word embeddings and algorithms of word2vec
Formulated idea for finishing in next couple of days.
No progress made on Markov model
Need to definitely make progress tomorrow

# Day 21
Made headway in markov model project of udacity NLP DL
Revised collections. 
Made Lookup table

# Day 22
Revised Word2vec algorithm with Siraj's video using GOT books
Revised PCA.


  
  
 

     
    
